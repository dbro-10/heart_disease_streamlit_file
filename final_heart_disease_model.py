# -*- coding: utf-8 -*-
"""final_heart_disease_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/dbro-10/first_machine_learning_for_heart_disease/blob/main/final_heart_disease_model.ipynb
"""

!pip install kagglehub -q
import kagglehub
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import os
import joblib

# Download dataset
path = kagglehub.dataset_download("redwankarimsony/heart-disease-data")
print("Path to dataset files:", path)

# Find CSV
csv_path = None
for file in os.listdir(path):
    if file.endswith('.csv'):
        csv_path = os.path.join(path, file)
        print(f"Found CSV: {csv_path}")
        break

df = pd.read_csv(csv_path)
print(f"Loaded: {df.shape}")
df.head()

print(df.info())
print("\nMissing Values:\n", df.isnull().sum())

plt.figure(figsize=(8,5))
sns.countplot(x='num', data=df)
plt.title('Original Target (0â€“4)')
plt.show()

df['target'] = df['num'].apply(lambda x: 0 if x == 0 else 1)
sns.countplot(x='target', data=df)
plt.title('Binarized Target (0=No, 1=Yes)')
plt.show()

X = df.drop(['id', 'num', 'target'], axis=1)
y = df['target']

cat_cols = X.select_dtypes(include='object').columns
num_cols = X.select_dtypes(include=['float64', 'int64']).columns

# Impute
X[cat_cols] = SimpleImputer(strategy='most_frequent').fit_transform(X[cat_cols])
X[num_cols] = SimpleImputer(strategy='mean').fit_transform(X[num_cols])

# Encode
for col in cat_cols:
    X[col] = LabelEncoder().fit_transform(X[col].astype(str))

# Scale
X[num_cols] = StandardScaler().fit_transform(X[num_cols])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print(f"Train: {X_train.shape}, Test: {X_test.shape}")

model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')
model.fit(X_train, y_train)
print("Model trained!")

y_pred = model.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(classification_report(y_test, y_pred))

sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)
importances.head(10).plot(kind='barh', color='teal')
plt.title('Top 10 Features')
plt.gca().invert_yaxis()
plt.show()

joblib.dump(model, 'heart_disease_model.pkl')
print("Model saved!")

# CELL 1: ROC-AUC Score
from sklearn.metrics import roc_auc_score
auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
print(f"ROC-AUC Score: {auc:.4f}")

# CELL 2: SHAP Explainer (Bias Audit) - FIXED
import shap
import matplotlib.pyplot as plt

# Create explainer
explainer = shap.TreeExplainer(model)

# Get SHAP values for POSITIVE class (target == 1)
# For binary classification, use index 1
shap_values = explainer.shap_values(X_test)

# Debug: Print type and shape
print(f"Type of shap_values: {type(shap_values)}")
if isinstance(shap_values, list):
    print(f"Number of classes: {len(shap_values)}")
    print(f"SHAP values shape per class: {shap_values[0].shape}, {shap_values[1].shape}")

# Use only the positive class SHAP values (class 1)
shap_positive = shap_values[1] if isinstance(shap_values, list) else shap_values

# Plot summary (bar plot of mean absolute SHAP value per feature)
shap.summary_plot(shap_positive, X_test, plot_type="bar", max_display=10)
plt.title("Feature Importance (Mean |SHAP Value|) - Heart Disease Risk")
plt.show()